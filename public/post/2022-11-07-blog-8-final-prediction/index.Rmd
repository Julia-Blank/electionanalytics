---
title: 'Blog 8: Final Prediction'
author: Julia Blank
date: '2022-11-07'
slug: []
categories: []
tags: []
---


```{r,echo = FALSE, warning = FALSE, message = FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE) 
# Loading in necessary libraries

library(tidyverse)
library(ggplot2)
library(stargazer)
library(janitor)
library(readxl)

library(tidyverse)
library(ggplot2)
library(blogdown)
library(stargazer)
library(readr)
library(usmap)
library(rmapshaper)
library(sf)
library(janitor)
library(tigris)
library(leaflet)
library(gridExtra)
library(grid)
library(ggthemes)
```

```{r, warning = FALSE, message = FALSE}
historical_results <- read_csv("/Users/juliablank/Documents/GOV 50 PROJECTS/electionanalytics/content/post/2022-10-03-blog-post-4-expert-prediction-and-incumbency/04-Incumbency-9-29-/Section-data/District-level-forecast/house party vote share by district 1948-2020.csv") %>%
  clean_names()

incumb_dist<- read_csv("/Users/juliablank/Documents/GOV 50 PROJECTS/electionanalytics/content/post/2022_10_17_blog_post_6_the_ground_game/06_Ground-Game_10-13/Section data/incumb_dist_1948-2020 (3).csv")

roper_cong_polls_1979_2022 <- read_csv("/Users/juliablank/Documents/GOV 50 PROJECTS/electionanalytics/content/post/2022-10-03-blog-post-4-expert-prediction-and-incumbency/04-Incumbency-9-29-/roper_cong_polls_1979-2022.csv")

cvap_district<- read_csv("/Users/juliablank/Documents/GOV 50 PROJECTS/electionanalytics/content/post/2022_10_17_blog_post_6_the_ground_game/06_Ground-Game_10-13/Section data/cvap_district_2012-2020_clean.csv")

polls_df <- read_csv("/Users/juliablank/Documents/GOV 50 PROJECTS/electionanalytics/content/post/2022_10_17_blog_post_6_the_ground_game/06_Ground-Game_10-13/Section data/house_polls_long.csv")

genericballot <- read_csv("/Users/juliablank/Documents/GOV 50 PROJECTS/electionanalytics/content/post/2022-10-24-blogpost-7-shocks/GenericPolls1942_2020.csv")

seatsdf <- read_csv("/Users/juliablank/Documents/GOV 50 PROJECTS/electionanalytics/content/post/2022-10-24-blogpost-7-shocks/Seats and Elections - Sheet1.csv")

party_power <- read_csv("/Users/juliablank/Documents/GOV 50 PROJECTS/electionanalytics/content/post/2022-10-24-blogpost-7-shocks/party_power.csv")

expert_ratings <- read_csv("/Users/juliablank/Documents/GOV 50 PROJECTS/electionanalytics/content/post/2022-10-03-blog-post-4-expert-prediction-and-incumbency/04-Incumbency-9-29-/Section-data/District-level-forecast/expert_rating.csv")


expert_rating_2022 <- read_csv("/Users/juliablank/Documents/GOV 50 PROJECTS/electionanalytics/content/post/2022-11-07-blog-8-final-prediction/expert_rating_2022-10-27.csv")


```

```{r, warning = FALSE, message = FALSE}
#create average rating
avg_ratings <- expert_ratings %>% 
  select(year, state, district, avg_rating)

#Create Incumbency Variables
dem_results_new <- incumb_dist %>%
    mutate(dem_status = case_when(DemStatus == "Incumbent" ~ 1,
                               TRUE ~ 0),
         rep_status = case_when(RepStatus == "Incumbent" ~ 1,
                               TRUE ~ 0))

# rename geoid
cvap_district <- cvap_district %>%
  rename(st_cd_fips = geoid) 

s <- which(avg_ratings$district < 10)

avg_ratings_clean <- avg_ratings %>%
  mutate(cd_fips = case_when(as.numeric(district) < 10 ~ paste0("0", district),
                                TRUE ~ district)) %>%
  rename(state_name = state) %>%
  mutate(district = case_when(
    district == "AL" ~ "1",
    TRUE ~ district
  ))  %>%
  drop_na()

training <- merge(cvap_district, dem_results_new, by = c('st_cd_fips', 'year')) 

party_power <- party_power %>%
  rename(year = Year)


#filter out generic ballot polls until 30 days or less pre election 
gbclean <- genericballot %>% 
  filter(days_until_election<30) %>%
  group_by(year) %>%
  mutate(gbavg_dem = mean(dem),
         gbavg_rep = mean(rep))

seats <- seatsdf %>%
  rename(year = Year) %>%
  rename(d_seats_up = `D Party Seats Up`,
         r_seats_up = `R Party Seats Up`)

training_data_vote <- training %>%
   mutate(totalvotes = RepVotes + DemVotes,
         turnout = (totalvotes/cvap)*100) %>%
  rename(state_name = state.x, 
         district = cd) %>%
  left_join(avg_ratings_clean, by = c("state_name", "district", "year")) %>%
  filter(year != 2022) %>%
  drop_na() %>%
  left_join(party_power, by = "year") %>%
  left_join(gbclean, by = "year") %>%
  left_join(seats, by = "year") %>%
  select(-sample_size)


seatshare <- training_data_vote %>%
  mutate(seatsharedem = case_when(DemVotesMajorPercent > 50.00 ~ 1,
                                  TRUE ~ 0),
         seatsharerep = case_when(RepVotesMajorPercent > 50.00 ~ 1,
                                  TRUE ~ 0))

```
**TLDR; If you read nothing else, my model predicts that democrats will win approximately 46.8427% of the two party vote share while Republicans will win 53.16% of the two party vote share for the House midterm election in 2022.**

Hi everyone! We’re back this week and ready for election day! This is the last stop on my election prediction journey and so I will take the time to synthesize my findings from the past 7 weeks to formally supply an estimation of the two party vote share outcome for the 2022 midterm elections. Today, I will walk you through every step of my process from variable consideration, to model evaluation, to prediction. I hope through reading this blog you will be able to understand how I've thought through the election and ways to make a robust model.

To start, after trying numerous methods, I decided to maximize interpretability and robustness of data by doing a national level model instead of a district level model. While doing a district level model definitely has some benefits when coming to predict seat share, I valued having a larger sample size to work with in my data over other advantages. My district level model data felt sparse which I think would hurt its predictive power when it encounters new data. As such, my model aggregates all variables on a national scale for a two party vote share prediction. 

The model predicts the dependent variable of Democratic Two Party Vote Share based on 5 predictors:

1. **Average Expert Prediction Rating**: the average expert rating of the political lean of a district (1-solidly Democratic - 7 solidly Republican)

2. **Generic Ballot Democrat Percentage**: the average generic ballot for democrats reported within 30 days of election 

3. **Incumbent Democratic President**: an indicator variable (1 or 0) that is 1 when the sitting president is a Democrat and 0 otherwise. 

4. **Democratic Seats to Defend**: the number of seats the democrats currently hold in the house

5. **Turnout**: the percentage of voters that cast a vote in a given district

![](/Users/juliablank/Documents/GOV 50 PROJECTS/electionanalytics/content/post/2022-11-07-blog-8-final-prediction/Screen Shot 2022-11-07 at 1.07.31 PM.png)

**Strategic and Academic Considerations**

When determining these 5 variables as my predictors, I think my main focus was creating a model that balanced being accurate on train data and being generalizable on new data like the uncertain midterm election. As such, I focused most on understanding how my model could capture the variation in elections holistically by looking at major themes across all elections but most importantly the 2022 midterm.

From reading contemporary articles about how voters are framing this election, very little has to do with each individual candidate's plans for their constituents and centers much more on the dynamics between the two party's. According to recent research conducted by the pew research center, voters feel both Republican and Democrat candidates have done an incredibly poor job at explaining their plans for the country. Instead, the election has been framed much more about how voters feel about the Democrat party remaining in control as they have since 2020. As such, most of the predictors I chose worked to shape or help explain voters views on the Democratic party. For instance, I included the indicator variable that represented when a president is currently a democrat or not. This variable allows my model to capture the influence of having a sitting democrat president on voter sentiment. Traditional theorists believe that oftentimes people's votes for a sitting President's party in midterms reflects their opinions of the status quo and so the party absorbs this sentiment in downballot races like the house. (Skelley and Rakich) Similarly, incorporating the results of generic ballots close within 30 days of an election allows me to have my model include a general temperature check of people's feelings about the party close to election day and measure its impact on election day party vote share. 

It is important to note that I had significant limitations on the amount of data I personally had access to. Since I fundamentally believe in the wisdom of crowds, I decided to make average expert rating a predictor in my variable. Experts forecasting elections and party lean have access to data behind pay walls and more advanced research methods. In addition, their models incorporate more advanced techniques and niche data that were beyond my capabilities to use and access in this course. As such, I found aggregating multiple expert forecasts on district lean served to be a helpful variable to try in my model. While at first I was skeptical about the potentially black box nature of this predictor, week after week it has performed well in my model and I feel pretty confident having the humility to defer to expert predictions in this sphere will serve me well in my final prediction. 

Additionally, I included turnout and number of seats the Democratic Party had in the house to defend in an election. While turnout typically has a statistically minimal effect, in tight races I do believe it will be important for Democrats looking to boost party vote share. Looking at correlation it has been After reading a paper by John T. Wooley, I was positively encouraged by the capability of current democratic seats in the house to explain election outcomes. Hist theory posits that the larger the number of seats that the party has currently to defend, the less successful they will be and the lower the their party vote share might be. For starters, with finite resources party's can only support so many candidates successfully and more importantly, the fewer seats the party holds the fewer it has to lose. 

All in all, holistically looking at historical literature and contemporary writings that posit the narrative of this midterm election have significantly contributed to my choice of predictors for this final model. Since I explained some of the theory behind their selection, I figured it would similarly be helpful to see the correlation of each variable on its own to party vote share. As such, I plotted each predictor against two party vote share in the graph below. 



**Examining Predictor Relationships Individually**
```{r}
##GRAPH INDEPENDENT VARIABLES RELATIONSHIP INDIVIDUALLY 

turnout_gg <-training_data_vote %>%
  ggplot() + 
  geom_point(aes(x = turnout, y = DemVotesMajorPercent)) +
  geom_smooth(aes(x = turnout, y = DemVotesMajorPercent, color = "Democrats"), method = "lm") + 
  geom_point(aes(x = turnout, y = RepVotesMajorPercent)) + 
  geom_smooth(aes(x = turnout, y = RepVotesMajorPercent, color = "Republicans"), method = "lm") +
  xlab("Turnout Percentage") +
  ylab("Party Vote Share") +
  labs(title = "Voter Turnout Percentage") +
  scale_color_manual(name = "Regression",             # legend name
                     values = c("Democrats" = "blue",  # map regression line colors
                                "Republicans" = "red")) +
  theme_classic()
 
 expertrating_gg <-training_data_vote %>%
  ggplot() + 
  geom_point(aes(x = avg_rating, y = DemVotesMajorPercent)) +
  geom_smooth(aes(x = avg_rating, y = DemVotesMajorPercent, color = "Democrats"), method = "lm") + 
  geom_point(aes(x = avg_rating, y = RepVotesMajorPercent)) + 
  geom_smooth(aes(x = avg_rating, y = RepVotesMajorPercent, color = "Republicans"), method = "lm") +
  xlab("Expert Rating Percentage") +
  ylab("Party Vote Share") +
  labs(title = "Expert Rating") +
  scale_color_manual(name = "Regression",             # legend name
                     values = c("Democrats" = "blue",  # map regression line colors
                                "Republicans" = "red")) +
  theme_classic()
 
 
 dem_status_gg <-training_data_vote %>%
  ggplot() + 
  geom_point(aes(x = dem_status, y = DemVotesMajorPercent, color = "light blue", alpha = 0.5)) +
  geom_smooth(aes(x = dem_status, y = DemVotesMajorPercent, color = "Democrats"), method = "lm") + 
  geom_point(aes(x = rep_status, y = RepVotesMajorPercent)) + 
  geom_smooth(aes(x = rep_status, y = RepVotesMajorPercent, color = "Republicans"), method = "lm") +
  xlab("Democrat Presidential Incumbency Percentage") +
  ylab("Party Vote Share") +
  labs(title = "Presidential Party Incumbency") +
  scale_color_manual(name = "Regression",             # legend name
                     values = c("Democrats" = "blue",  # map regression line colors
                                "Republicans" = "red")) +
  theme_classic()

  
genericballot_gg<-training_data_vote %>%
  ggplot() + 
  geom_point(aes(x = gbavg_dem, y = DemVotesMajorPercent)) +
  geom_smooth(aes(x = gbavg_dem, y = DemVotesMajorPercent, color = "Democrats"), method = "lm") + 
  geom_point(aes(x = gbavg_rep, y = RepVotesMajorPercent)) + 
  geom_smooth(aes(x = gbavg_rep, y = RepVotesMajorPercent, color = "Republicans"), method = "lm") +
  xlab("Generic Ballot Averages") +
  ylab("Party Vote Share") +
  labs(title = "Generic Ballot Averages") +
  scale_color_manual(name = "Regression",             # legend name
                     values = c("Democrats" = "blue",  # map regression line colors
                                "Republicans" = "red")) +
  theme_classic()


seatsup_gg <- training_data_vote %>%
  ggplot() + 
  geom_point(aes(x = d_seats_up, y = DemVotesMajorPercent)) +
  geom_smooth(aes(x = d_seats_up, y = DemVotesMajorPercent, color = "Democrats"), method = "lm") + 
  geom_point(aes(x = r_seats_up, y = RepVotesMajorPercent)) + 
  geom_smooth(aes(x = r_seats_up, y = RepVotesMajorPercent, color = "Republicans"), method = "lm") +
  xlab("Current Seats Held by Party") +
  ylab("Party Vote Share") +
  labs(title = "Seats Held by Party") +
  scale_color_manual(name = "Regression",             # legend name
                     values = c("Democrats" = "blue",  # map regression line colors
                                "Republicans" = "red")) +
  theme_classic()

grid.arrange(turnout_gg, expertrating_gg, dem_status_gg, genericballot_gg, seatsup_gg, nrow = 3, top=textGrob("Linear Regression of Party Vote Share vs. Predictors"))
```

As can be seen above 


#Model Results 

```{r, warning = FALSE, message = FALSE}
#seatssimple <- lm(DemVotesMajorPercent ~ turnout + avg_rating + dem_status + d_seats_up , training_data)
#repseatssimple <- lm(RepVotesMajorPercent~ turnout + avg_rating + rep_status + r_seats_up , training_data)
gbincludedseats <- lm(DemVotesMajorPercent ~ avg_rating + gbavg_dem + dem_status + d_seats_up + turnout, training_data_vote)
gbincludedseatsrep <- lm(RepVotesMajorPercent ~ avg_rating + gbavg_dem + dem_status + d_seats_up + turnout, training_data_vote)
#seatshareattempt <- lm(seatsharedem ~ turnout + avg_rating + dem_status + d_seats_up + gbavg_dem, seatshare)

stargazer(gbincludedseats, type = "text",
          column.labels = c("Final Election Prediction"),
          covariate.labels = c("Expert Rating", "Generic Ballot Democrat Percent", "Incumbent Democrat President", "Dem Seats", "Turnout"),
          dep.var.labels = "Democratic Vote Percentage",
          header=FALSE,
          single.row = TRUE,
          no.space = TRUE,
          column.sep.width = "1pt",
          font.size = "small")
```

As can be seen in the stargazer above, every variable is significant at the 99% confidence interval with a p-value less than 0.01. 

1. **Average Expert Prediction Rating**: In my model, average expert rating has a coefficient of **-3.059**. This can be interpreted as for any increase in one point of expert rating, the predicted Democratic Two Party Vote Share Percentage decreases by -3.059. This makes sense since an increase in a point on the scale of expert ratings increases the experts confidence in how solidly Republican a region is. 

2. **Generic Ballot Democrat Percentage**: In my model, generic ballot democrat percentage has a coefficient of **0.459**. This can be interpreted as for every increase in 1 percentage for the average democrat percentage of generic ballots taken with 30 days of the election, there is an approximate 0.459 increase in Democratic Vote Share Percentage. This makes sense since 

3. **Incumbent Democratic President**: In my model, the incumbent democrat president variable (dem_status) has a coefficient of as a coefficient of **-0.644**. This means that if a sitting president is a Democrat, then the house Democratic Two Party Vote Share will approximately decrease by 0.644 percent. Given the nature of midterm elections, which are often referendums on the sitting president and his status quo, this negative coefficient makes sense. 

4. **Democratic Seats to Defend**: In my model, the democratic seats to defend variable (dem seats) has a coefficient of **-0.064**. This means that for every additional seat the democrats currently hold and must defend in the house, their Democrat Vote Share percentage will decrease by approximately 0.064.

5. **Turnout**: In my model, the turnout variable has a coefficient of **-0.044**. This means that for every increase in one percent of turnout the democratic vote percentage decreases by -0.044 percent. While this coefficient does seem dubious given the small positive correlation between turnout and democratic vote share, in conjunction with the rest of my model perhaps turnout is being used to adjust vote percentage along with other variables. 


# MODEL PREDICTION

Ultimately, the goal of creating the model is to then predict the outcome of tomorrow's 2022 midterm election in the house. As discussed earlier, I aim to predict two party vote share in the house. After wrangling the data for 2022 as of 11/07, **my model predicts that democrats will win approximately 46.84% of the two party vote share while Republicans will win 53.16% of the two party vote share for the house**. At a 95% confidence interval, my model's lower bound for democrat vote share percentage is approximately 41.2% while the upper bound is 52.49%. While this prediction may seem wide, it does seem on trend with the conversation going on in the election world even as of today. According to today's New York Times article, the election seems incredibly close and could swing either way despite a significantly easier path to House dominance by the Republican party. As such, I think this model's conclusion is fair and a likely outcome. However, to more formally analyze the validity of this model I used both in sample and out of sample metrics of evaluation. 

First off, looking at my model, it has an adjusted r-squared value of 0.761. While this is not a perfect r-squared, I do have confidence in the model's ability to predict off the data fairly well. In examining my models predictive capabilities, I graphed a plot of the models predictions on the training data against the actual values of Democratic vote share. As can be seen, the model looks very accurate for midterm years like 2014 and 2018, as well as 2020. The years where this model strayed from the data was in 2012 and 2016. I'm not surprised by the degree to which 2016 is off since my model is based significantly on polls and expert predictions, which proved incredibly fallible in the 2016 election. As such, I continue to have confidence in my models predictions and am encouraged by the models accuracy during midterm years in the data set. 

```{r}
## VOTE share Predictions

##CREATE TEST DATA
expert_rating_2022_clean <- expert_rating_2022 %>%
  mutate(cd_fips = case_when(as.numeric(district) < 10 ~ paste0("0", district),
                                TRUE ~ district)) %>%
  rename(state_name = state) %>%
  mutate(district = case_when(
    district == "AL" ~ "1",
    TRUE ~ district
  ))  %>%
  drop_na()

expert_rating_2022_clean$avg_rating = rowMeans(expert_rating_2022_clean[,c('cook', 'rothenberg', 'sabatos_crystal_ball', 'real_clear', 'fivethirtyeight', 'ddhq', 'politico', 'fox', 'the_economist')], na.rm=TRUE)

avg_2022_nat<- expert_rating_2022_clean %>%
  summarize(mean(avg_rating))


#avg_rating = 4.085592

#today's gb dem = 45.5

#todays' gb rep = 46.6

#50.24418 turnout

#1 = dem_status

#d_seats_up = 222

#r_seats_up = 213

#rep_status = 0


test_data_nat <- data.frame(turnout = 50.24418, 
         avg_rating = 4.085592,
         gbavg_dem = 45.5, 
         gbavg_rep = 46.6,
         dem_status = 1, 
         rep_status = 0, 
         d_seats_up = 222,
         r_seats_up = 213)

dem_vote_share <- predict(gbincludedseats, test_data_nat, interval = "prediction", level = 0.95)

rep_vote_share <- predict(gbincludedseatsrep, test_data_nat, interval = "prediction")

```


```{r}

preddata <- training_data_vote %>%
  group_by(year) %>%
  summarize(turnout = mean(turnout), dem_status = mean(dem_status), avg_rating = mean(avg_rating), d_seats_up = mean(d_seats_up), gbavg_dem = mean(gbavg_dem), DemVotesMajorPercent = mean(DemVotesMajorPercent))


regressionprediction <-preddata %>%
  ggplot(aes(x = predict(gbincludedseats, preddata), y = DemVotesMajorPercent, label = year))  +
  geom_abline(intercept = 0, slope = 1, color = "red") +
  geom_text() +
  xlab("Predicted Democratic Vote Share") +
  ylab("Actual Democratic Vote Share") +
  labs(title = "Model Prediction Accuracy") + 
  theme_economist()

regressionprediction
```

Additionally, in evaluating the in-sample errors in the model I checked to make sure there wasn't any significant skew. Looking at a histogram of the residuals below, I can see that the errors are approximately normally distributed. Since normality of residuals is an assumption of a linear model, this proves the assumption valid for my national level model and gives me more confidence in my linear model predictions.

```{r}

#INSAMPLE R^2: 0.761
modelr_2 <- summary(gbincludedseats)$r.squared

#INSAMPLE ERROR

##GRAPH OF RESIDUALS
hist(gbincludedseats$model$DemVotesMajorPercent -
gbincludedseats$fitted.values,
main="Histogram of Actual Dem Vote Share - Predicted Dem Vote Share",
xlab = "Residual of Predictions", col = "blue")

##EVALUATE MSE

mse_model <- mean((gbincludedseats$model$DemVotesMajorPercent -gbincludedseats$fitted.values)^2)

mseeval <- sqrt(mse_model)


```

```{r}
#OUTSAMPLE MODEL 

outsamp_mod1 <- lm(DemVotesMajorPercent ~ turnout + avg_rating + dem_status + d_seats_up + gbavg_dem,

training_data_vote[training_data_vote$year != 2018,])
outsamp_pred <- predict(outsamp_mod1,

training_data_vote[training_data_vote$year == 2018,])

                                                       
```

In addition to conducting in-sample evaluation, I also conducted out of sample evaluation in order to evaluate my model and its sensitivity to given data points. Looking at cross validation error, my model had approximately 1.58124, which while not optimal is much  lower than many of my other previous models.

```{r}
##CROSS VALIDATION

#DemVotesMajorPercent ~ turnout + avg_rating + dem_status + d_seats_up + gbavg_dem

years_outsamp <- sample(training_data_vote$year, 4)
mod <- lm(DemVotesMajorPercent ~ turnout + avg_rating + dem_status + d_seats_up + gbavg_dem, 
  training_data_vote[!(training_data_vote$year %in% years_outsamp),])

outsamp_pred <- predict(mod,
                        newdata = training_data_vote[training_data_vote$year %in%
                          years_outsamp,])



crossvalerror <- mean(outsamp_pred - training_data_vote$DemVotesMajorPercent[training_data_vote$year %in% years_outsamp])
```

#LIMITATIONS

Overall, my largest limitation was definitely sample size. Statistics has shown time and time again that with small sample size comes increased bias and weaker models. House election data is very hard to find and even more so on a district level. My model got limited by the average expert predictions variable which didn't have data points before 2010. As such, my model didn't have enough elections to train on. This is one of the reasons I chose to use a national level model that aggregates district data into one prediction model rather than a district level model that contains an individual predictive model for each district and then aggregates each prediction, as each district only had 1-2 data points. Additionally, since my data predicts overall two party vote share, who actually controls the House and by how many seats could be different from dominance in my prediction. Without clear means for accounting for redistricting in my national level model, I felt efforts to tackle seat share predictions may not be sufficient or valuable. Overall, I'm proud of what I have put together but am incredibly cognizant that my models predictive power could be higher. 




#CONCLUSION

All in all, I'm eagerly awaiting election results and do believe my model has accurately predicted Republican dominance of the two party vote share. In reflecting on my model, I chose to present my national level prediction in its simplest form rather than one of my more technically advanced or flashy models made such as a pooled district model. Following the advice of Gary C. Jacobson, I chose to go for a simpler more robust model rather than a technical but data sparse model. I hope I made the right choice but looking at my final predictions of 46.84% for the Democratic Two Party Vote Share versus the 53.16% for Republicans, I feel fairly confident in the results. Ultimately, looking at the themes of this election, it feels as thought decisions are going to be made by reviewing sentiments towards the Democratic Party in the past two years instead of on a candidate by candidate or race by race basis. I look forward to evaluating this theory post election day and dissecting the psychological components and motivators behind the electoral outcome soon.


#CITATIONS: 

Geoffreyvs. (2022, January 3). Why the president's party almost always has a bad midterm. FiveThirtyEight. Retrieved November 7, 2022, from https://fivethirtyeight.com/features/why-the-presidents-party-almost-always-has-a-bad-midterm/ 

Jacobson, Gary C. “ The 2022 U.S. Midterm Election: A Conventional Referendum or Something Different ?” Dropbox, University of California, San Diego, https://www.dropbox.com/s/95s7hip8bzg5x8n/Jacobson%202022%20Essay.pdf?dl=0. 

Schaeffer, K., &amp; Green, T. V. (2022, November 3). Key facts about U.S. voter priorities ahead of the 2022 midterm elections. Pew Research Center. Retrieved November 7, 2022, from https://www.pewresearch.org/fact-tank/2022/11/03/key-facts-about-u-s-voter-priorities-ahead-of-the-2022-midterm-elections/ 

“The 2022 Midterm Elections: What the Historical Data Suggest.: The American Presidency Project.” The 2022 Midterm Elections: What the Historical Data Suggest. | The American Presidency Project, 30 Aug. 2022, https://www.presidency.ucsb.edu/analyses/the-2022-midterm-elections-what-the-historical-data-suggest. 

```{r}
#outsamp_errors <- sapply(1:1000, function(i){
#years_outsamp <- sample(training_data_vote$year, 3)

#outsamp_mod <- lm(DemVotesMajorPercent ~ turnout + avg_rating + dem_status + d_seats_up + gbavg_dem,
#training_data_vote[!(training_data_vote$year %in% years_outsamp),])

#outsamp_pred <- predict(outsamp_mod,
                      #  newdata = training_data_vote[training_data_vote$year %in% years_outsamp,])

#outsamp_true <- training_data_vote$DemVotesMajorPercent[training_data_vote$year %in% years_outsamp]
#mean(outsamp_pred - outsamp_true)
#})
```


```{r}
# popvote <- read_csv("/Users/juliablank/Documents/GOV 50 PROJECTS/electionanalytics/Economic Section data/house_popvote_seats.csv") 
# 
# train <- popvote %>% 
#   mutate(dem_status = case_when(president_party == "D" ~ 1,
#                                TRUE ~ 0),
#           rep_status = case_when(president_party == "R" ~ 1,
#                                TRUE ~ 0))
# 
# party_power2 <- party_power %>%
#   rename(year = Year)
# 
# #filter out generic ballot polls until 30 days or less pre election 
# gbnew <- genericballot %>% 
#   filter(days_until_election<30) %>%
#   group_by(year) %>%
#   mutate(gbavg_dem = mean(dem),
#          gbavg_rep = mean(rep))
# 
# seats2 <- seatsdf %>%
#   rename(year = Year) %>%
#   rename(d_seats_up = `D Party Seats Up`,
#          r_seats_up = `R Party Seats Up`)
# 
# new_train_natty <- train %>%
#   left_join(gbnew, by = "year") %>%
#   left_join(seats2, by = "year")
# 
# y_val <- lm(D_seats ~ gbavg_dem + dem_status + d_seats_up, new_train_natty)
# 
# stargazer(y_val, type = "text")
```
